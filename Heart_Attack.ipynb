{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8fe8893-a898-4510-b105-32b92d453fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt   \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Heart_Attack = pd.read_csv(\"Heart Attack.csv\")\n",
    "Heart_Attack.head()\n",
    "\n",
    "\n",
    "\n",
    "X = Heart_Attack['glucose'] #Assign the column “glucose” as your feature data\n",
    "y = Heart_Attack['class']  #Assign the column \"class\" as your target variable\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Split data into temporary training and test sets (80% training, 20% test)\n",
    "X_train_temporary, X_test, y_train_temporary, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Split the temporary training set into final training and validation sets (80% training, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_temporary, y_train_temporary, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5974d515-2f22-41b0-9423-03c22de1cdbf",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c30b726-3a29-4f31-a30a-c5865aca2cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.07      0.13       101\n",
      "    positive       0.63      0.98      0.76       163\n",
      "\n",
      "    accuracy                           0.63       264\n",
      "   macro avg       0.63      0.52      0.44       264\n",
      "weighted avg       0.63      0.63      0.52       264\n",
      "\n",
      "[[  7  94]\n",
      " [  4 159]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "#Create a Logistic Regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "#Train the model on the training data\n",
    "model.fit(X_train.values.reshape(-1, 1), y_train)\n",
    "\n",
    "#Make predictions on the test data\n",
    "y_pred = model.predict(X_test.values.reshape(-1, 1))\n",
    "\n",
    "#Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "#Print classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3974df49-0ab5-4896-9301-1996341303ae",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e5a9be5-440d-41ab-b451-01e2f6705af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.36      0.35      0.36       101\n",
      "    positive       0.61      0.63      0.62       163\n",
      "\n",
      "    accuracy                           0.52       264\n",
      "   macro avg       0.49      0.49      0.49       264\n",
      "weighted avg       0.51      0.52      0.52       264\n",
      "\n",
      "[[ 35  66]\n",
      " [ 61 102]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "#Create a Random Forest classifier with 100 trees\n",
    "model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "#Train the model on the training data\n",
    "model_rf.fit(X_train.values.reshape(-1, 1), y_train)\n",
    "\n",
    "#Make predictions on the test data\n",
    "y_pred_rf = model_rf.predict(X_test.values.reshape(-1, 1))\n",
    "\n",
    "#Evaluate the model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf:.2f}\")\n",
    "\n",
    "#Print classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64dd858f-6647-42e2-b154-949024706744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Best Random Forest Accuracy: 0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.35      0.19      0.24       101\n",
      "    positive       0.61      0.78      0.68       163\n",
      "\n",
      "    accuracy                           0.55       264\n",
      "   macro avg       0.48      0.48      0.46       264\n",
      "weighted avg       0.51      0.55      0.51       264\n",
      "\n",
      "[[ 19  82]\n",
      " [ 36 127]]\n"
     ]
    }
   ],
   "source": [
    "#In order to get a higher Accuracy-score, I will perform a Grid Search to find the best hyperparamters for the Random Forest Classifier.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "#Define the hyperparameters to search through\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],          \n",
    "    'max_depth': [None, 5, 10, 15],         \n",
    "    'min_samples_split': [2, 5, 10]          \n",
    "}\n",
    "\n",
    "#Set up Grid Search with cross-validation (using the validation set)\n",
    "grid_search = GridSearchCV(model_rf, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "#Fit the Grid Search to find the best hyperparameters\n",
    "grid_search.fit(X_val.values.reshape(-1, 1), y_val)\n",
    "\n",
    "#Get the best hyperparameters found by Grid Search\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)\n",
    "\n",
    "# Create a new Random Forest classifier with the best hyperparameters\n",
    "best_model_rf = RandomForestClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#Train the best model on the training data\n",
    "best_model_rf.fit(X_train.values.reshape(-1, 1), y_train)\n",
    "\n",
    "#Make predictions on the test data using the best model\n",
    "y_pred_best_rf = best_model_rf.predict(X_test.values.reshape(-1, 1))\n",
    "\n",
    "#Evaluate the best model\n",
    "accuracy_best_rf = accuracy_score(y_test, y_pred_best_rf)\n",
    "print(f\"Best Random Forest Accuracy: {accuracy_best_rf:.2f}\")\n",
    "\n",
    "#Print classification report and confusion matrix for the best model\n",
    "print(classification_report(y_test, y_pred_best_rf))\n",
    "print(confusion_matrix(y_test, y_pred_best_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c0e1bea-e767-4292-b5b5-29985a317db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       101\n",
      "    positive       0.62      1.00      0.76       163\n",
      "\n",
      "    accuracy                           0.62       264\n",
      "   macro avg       0.31      0.50      0.38       264\n",
      "weighted avg       0.38      0.62      0.47       264\n",
      "\n",
      "[[  0 101]\n",
      " [  0 163]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Since the accuracy-score is still pretty low, I decided to try my luck with an SVM model\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Create an SVM classifier with a linear kernel\n",
    "model_svm = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "#Train the model on the training data\n",
    "model_svm.fit(X_train.values.reshape(-1, 1), y_train)\n",
    "\n",
    "#Make predictions on the test data\n",
    "y_pred_svm = model_svm.predict(X_test.values.reshape(-1, 1))\n",
    "\n",
    "#Evaluate the model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Accuracy: {accuracy_svm:.2f}\")\n",
    "\n",
    "#Print classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8531a075-5a73-4a25-9eba-5c19737dfd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.38      0.46       101\n",
      "    positive       0.68      0.83      0.75       163\n",
      "\n",
      "    accuracy                           0.66       264\n",
      "   macro avg       0.63      0.61      0.60       264\n",
      "weighted avg       0.65      0.66      0.64       264\n",
      "\n",
      "[[ 38  63]\n",
      " [ 27 136]]\n"
     ]
    }
   ],
   "source": [
    "#Since one's heart health deteroriates over the years, I also wanted to train some models using the variable \"age\" as a predictor\n",
    "\n",
    "X2 = Heart_Attack['age'] \n",
    "y2 = Heart_Attack['class']\n",
    "\n",
    "#80/10/10 split again\n",
    "X_train_temporary, X_test, y_train_temporary, y_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_temporary, y_train_temporary, test_size=0.5, random_state=42)\n",
    "\n",
    "#Create a LR model\n",
    "model_logistic = LogisticRegression(random_state=42)\n",
    "\n",
    "#Train the model on the training data\n",
    "model_logistic.fit(X_train.values.reshape(-1, 1), y_train)\n",
    "\n",
    "#Make predictions on the test data\n",
    "y_pred_logistic = model_logistic.predict(X_test.values.reshape(-1, 1))\n",
    "\n",
    "#Evaluate the model\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_logistic:.2f}\")\n",
    "\n",
    "#Print classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred_logistic))\n",
    "print(confusion_matrix(y_test, y_pred_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fad7d489-dd67-4539-8c1b-3601f14f7612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.25      0.38        55\n",
      "    positive       0.64      0.94      0.76        77\n",
      "\n",
      "    accuracy                           0.65       132\n",
      "   macro avg       0.69      0.59      0.57       132\n",
      "weighted avg       0.68      0.65      0.60       132\n",
      "\n",
      "[[14 41]\n",
      " [ 5 72]]\n"
     ]
    }
   ],
   "source": [
    "#Achieving a higher accuracy with \"age\" as a predictor compared to \"glucose\" \n",
    "#indicates that age might be a more informative feature for predicting heart attack outcomes in this specific dataset.\n",
    "#Since as we age, the pancreas produces less insulin, blood sugar remains elevated for longer - Therefore I decided to create one last model,\n",
    "#which combines both features, \"age\" and \"glucose\"\n",
    "\n",
    "\n",
    "# Separate features and target variable\n",
    "X3 = Heart_Attack[['age', 'glucose']]\n",
    "y3 = Heart_Attack['class']\n",
    "\n",
    "# 80/10/10 split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X3, y3, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "#Create a Logistic Regression model\n",
    "model_logistic = LogisticRegression(random_state=42)\n",
    "\n",
    "#Train the model on the training data\n",
    "model_logistic.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions on the test data\n",
    "y_pred_logistic = model_logistic.predict(X_test)\n",
    "\n",
    "#Evaluate the model\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_logistic:.2f}\")\n",
    "\n",
    "#Print classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred_logistic))\n",
    "print(confusion_matrix(y_test, y_pred_logistic))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9426cbdc-3e93-4ade-882e-e2f604320116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.25      0.38        55\n",
      "    positive       0.64      0.94      0.76        77\n",
      "\n",
      "    accuracy                           0.65       132\n",
      "   macro avg       0.69      0.59      0.57       132\n",
      "weighted avg       0.68      0.65      0.60       132\n",
      "\n",
      "[[14 41]\n",
      " [ 5 72]]\n"
     ]
    }
   ],
   "source": [
    "#Since this model only got an accuracy of 0.65, I decided to try and increase it by using Feature Scaling\n",
    "#Since \"age\" and \"glucose\" have different scales, \n",
    "#applying feature scaling helps bring them to a similar range. \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X3)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_standardized, y3, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "#Create a Logistic Regression model\n",
    "model_logistic = LogisticRegression(random_state=42)\n",
    "\n",
    "#Train the model on the training data\n",
    "model_logistic.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions on the test data\n",
    "y_pred_logistic = model_logistic.predict(X_test)\n",
    "\n",
    "#Evaluate the model\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_logistic:.2f}\")\n",
    "\n",
    "\n",
    "#Print classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred_logistic))\n",
    "print(confusion_matrix(y_test, y_pred_logistic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14b09cc0-2bb1-47fd-9b91-d217e05739e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.49      0.42      0.45        55\n",
      "    positive       0.62      0.69      0.65        77\n",
      "\n",
      "    accuracy                           0.58       132\n",
      "   macro avg       0.56      0.55      0.55       132\n",
      "weighted avg       0.57      0.58      0.57       132\n",
      "\n",
      "[[23 32]\n",
      " [24 53]]\n"
     ]
    }
   ],
   "source": [
    "#Since we have gotten 2 features and a moderate sample size, I will try running a Random Forest Model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf:.2f}\")\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fd157bf-97fe-4d65-aac9-1fffd0fbd7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will have to rest my case, and accept that with this data and my models, the Logistic regression Model using only the feature \"Age\", \n",
    "#gives the highest prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6fc76bf-698d-4609-b0c4-fe5aaabfe2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary table\n",
    "\n",
    "import pandas as pd  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "summary_results = {'algorithm': ['Logistic Regression', \"Random Forest\", \"Random Forest\", \"SVM\", \"Logistic Regression\", \n",
    "                                 \"Logistic Regression\", \"Logistic Regression\", \"Random Forest\" ],\n",
    "                   \n",
    "                   \n",
    "'data': [\"y\", \"y\", \"y\", \"y\", \"y2\", \"y3\", \"y3 (X3=scaled)\", \"y3 (X3=scaled)\" ],\n",
    "                   \n",
    "'hyperparameter': ['random_state=42', \"{n_estimators=100, random_state=42}\",\"{'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 150}\",\n",
    "                  \"{kernel='linear', random_state=42}\", \"random_state=42\", \"random_state=42\", \"random_state=42\", \"random_state=42\" ],\n",
    "                   \n",
    "'accuracy': [0.63, 0.52, 0.55, 0.62, 0.66, 0.65, 0.65, 0.58]}\n",
    "\n",
    "#create a df from the results dictionary\n",
    "summary_table = pd.DataFrame(summary_results)\n",
    "\n",
    "#save the summary table as a CSV file\n",
    "summary_table.to_csv('summary_table.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
